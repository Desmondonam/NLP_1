{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGty7iHoU3RHntdChAm+fy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Desmondonam/NLP_1/blob/main/Components_of_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP\n",
        "\n",
        "- Natural Language Processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and human language. It involves enabling machines to understand, interpret, and generate human language in a way that is both meaningful and useful.\n",
        "\n",
        "## Key Components of NLP:\n",
        "- **Text Preprocessing:** Cleaning and preparing text data for analysis. This includes tasks like tokenization (splitting text into words or sentences), removing stopwords, and stemming or lemmatization (reducing words to their base form).\n",
        "\n",
        "- **Text Representation:** Converting text into numerical format that a machine can process. Common techniques include:\n",
        "\n",
        "  - **Bag of Words (BoW):** Represents text as a collection of word counts or frequencies.\n",
        "  - **TF-IDF:** Weighs terms by their frequency and importance across documents.\n",
        "  - **Word Embeddings:** Dense vector representations of words, capturing semantic meaning (e.g., Word2Vec, GloVe).\n",
        "  - **Sentiment Analysis:** Determining the sentiment or emotion expressed in a piece of text (e.g., positive, negative, neutral).\n",
        "\n",
        "  - **Named Entity Recognition (NER):** Identifying and classifying entities in text (e.g., names of people, places, organizations).\n",
        "\n",
        "  - **Machine Translation:** Translating text from one language to another using models like Google's Transformer.\n",
        "\n",
        "  - **Text Classification:** Assigning predefined categories or labels to text (e.g., spam detection in emails).\n",
        "\n",
        "  - **Language Generation:** Producing human-like text, such as writing essays, summaries, or even creative content.\n",
        "\n",
        "  - **Speech Recognition and Synthesis:** Converting spoken language into text (speech recognition) and generating spoken language from text (speech synthesis).\n",
        "\n",
        "### Applications of NLP:\n",
        "- **Chatbots and Virtual Assistants:** Automating customer service and providing conversational interfaces.\n",
        "- **Search Engines:** Enhancing search capabilities by understanding user queries better.\n",
        "- **Content Recommendation:** Suggesting relevant content based on user interests.\n",
        "- **Healthcare:** Analyzing clinical notes, automating diagnostics, and managing patient data.\n",
        "\n",
        "NLP is a rapidly evolving field with applications across various industries, leveraging the power of AI to understand and generate human language."
      ],
      "metadata": {
        "id": "qBB0JdfHy8Od"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkSgKe36ytHR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text preprocessing\n",
        "- We'll use a public dataset, the IMDb movie reviews dataset, which is available through the nltk library."
      ],
      "metadata": {
        "id": "0vP6B1TW0zab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Import Libraries\n",
        "First, you'll need to install and import the necessary libraries."
      ],
      "metadata": {
        "id": "-vQcCUva1DBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sj8mNC9d01ZM",
        "outputId": "1e13fb03-81b6-4099-db40-fdb883786b53"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Load the Dataset\n",
        "For this example, we’ll use the IMDb movie reviews dataset. If you don’t have a dataset in a CSV file, you can load it directly from nltk or another source."
      ],
      "metadata": {
        "id": "xw10fWfq1Ncn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset from nltk\n",
        "from nltk.corpus import movie_reviews\n",
        "nltk.download('movie_reviews')\n",
        "\n",
        "# Load the dataset into a DataFrame\n",
        "documents = [(list(movie_reviews.words(fileid)), category)\n",
        "             for category in movie_reviews.categories()\n",
        "             for fileid in movie_reviews.fileids(category)]\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(documents, columns=['review', 'sentiment'])\n",
        "\n",
        "# Preview the dataset\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sz38kuUp1I3a",
        "outputId": "4ee22f67-da0a-4157-fba2-2f80b446fb21"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review sentiment\n",
            "0  [plot, :, two, teen, couples, go, to, a, churc...       neg\n",
            "1  [the, happy, bastard, ', s, quick, movie, revi...       neg\n",
            "2  [it, is, movies, like, these, that, make, a, j...       neg\n",
            "3  [\", quest, for, camelot, \", is, warner, bros, ...       neg\n",
            "4  [synopsis, :, a, mentally, unstable, man, unde...       neg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Text Preprocessing\n",
        "1. Lowercasing\n",
        "- Convert all the text to lowercase to ensure uniformity."
      ],
      "metadata": {
        "id": "UYvjes_01XN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to lowercase\n",
        "df['review'] = df['review'].apply(lambda x: [word.lower() for word in x])\n"
      ],
      "metadata": {
        "id": "K-_Gajhs1TLO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Tokenization\n",
        "- Tokenize the text into individual words or sentences."
      ],
      "metadata": {
        "id": "bZTyA60J1hzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization (already done in the loading process)\n",
        "df['review'] = df['review'].apply(lambda x: word_tokenize(' '.join(x)))\n",
        "\n",
        "# Example for sentence tokenization (if you have large text):\n",
        "# df['review'] = df['review'].apply(lambda x: sent_tokenize(' '.join(x)))\n"
      ],
      "metadata": {
        "id": "olqsLLPc1eIm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Removing Stopwords\n",
        "- Remove common stopwords that do not contribute significant meaning."
      ],
      "metadata": {
        "id": "SCFefeUC1uR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Remove stopwords\n",
        "df['review'] = df['review'].apply(lambda x: [word for word in x if word not in stop_words])\n"
      ],
      "metadata": {
        "id": "ZayI2xik1nIf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Removing Punctuation and Non-Alphabetic Characters\n",
        "- Remove punctuation and non-alphabetic characters."
      ],
      "metadata": {
        "id": "O-o9CaDM119S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove punctuation and non-alphabetic characters\n",
        "df['review'] = df['review'].apply(lambda x: [re.sub(r'\\W+', '', word) for word in x if word.isalpha()])\n"
      ],
      "metadata": {
        "id": "Lv7JBJjk1yrx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Stemming\n",
        "- Reduce words to their root form using stemming."
      ],
      "metadata": {
        "id": "mUwcH1mX1_Fi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize stemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Apply stemming\n",
        "df['review'] = df['review'].apply(lambda x: [stemmer.stem(word) for word in x])\n"
      ],
      "metadata": {
        "id": "GsYyAqNr16Qr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Lemmatization\n",
        "- Alternatively, you can use lemmatization, which considers the context and converts words to their base form."
      ],
      "metadata": {
        "id": "hgIUXpCi2MZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Apply lemmatization\n",
        "df['review'] = df['review'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n"
      ],
      "metadata": {
        "id": "85aDVoUv2EwO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Joining Tokens Back into Sentences\n",
        "- After processing, you may want to join the tokens back into a single string."
      ],
      "metadata": {
        "id": "aVdUo-jV2X0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Join tokens back into a string\n",
        "df['cleaned_review'] = df['review'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "# Preview the cleaned text\n",
        "print(df['cleaned_review'].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4mNzxpL2Q7a",
        "outputId": "339546a5-1d94-44ac-c48b-62749d548e81"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    plot two teen coupl go church parti drink driv...\n",
            "1    happi bastard quick movi review damn bug got h...\n",
            "2    movi like make jade movi viewer thank invent t...\n",
            "3    quest camelot warner bro first featur length f...\n",
            "4    synopsi mental unstabl man undergo psychothera...\n",
            "Name: cleaned_review, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Save or Continue with Further NLP Tasks\n",
        "- Now that you’ve preprocessed the text data, you can save it to a file for future use or proceed with further NLP tasks such as sentiment analysis, classification, etc."
      ],
      "metadata": {
        "id": "jk7pwZWr2hNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to CSV\n",
        "df.to_csv('cleaned_movie_reviews.csv', index=False)\n"
      ],
      "metadata": {
        "id": "R18nZ-zF2cfJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hz4qFfsO2p09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary:\n",
        "- **Lowercasing:** Standardizes text by converting everything to lowercase.\n",
        "- **Tokenization:** Splits text into words or sentences.\n",
        "- **Stopwords Removal:** Eliminates common, insignificant words.\n",
        "- **Punctuation Removal:** Cleans text by removing punctuation and non-alphabetic characters.\n",
        "- **Stemming/Lemmatization:** Reduces words to their root or base form to handle variations."
      ],
      "metadata": {
        "id": "edAgKNyY2-Bc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HCEUKSV73YNb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}